import { BlogPost } from "../blogs";

export const BLOGS_PART_58: BlogPost[] = [
    {
        slug: "iso-invariance-digital-sensor",
        title: "The Lie of ISO: How Sensors Work",
        description: "In film, ISO meant chemistry. In digital, ISO is just volume. Why shooting at ISO 100 and ISO 1600 might be exactly the same thing.",
        category: "Photography",
        publishedAt: "2024-12-20",
        imageUrl: "/images/iso-noise.png",
        tags: ["Photography", "Tech", "Physics", "Deep Dive"],
        content: `
## Introduction: The Photon Bucket
Imagine a pixel is a bucket.
Photons are rain.
Shutter Speed = How long you leave the bucket in the rain.
Aperture = How wide the bucket is.
**ISO is not exposure.**
ISO is just taking the water in the bucket and *pretending* there is more.
It is amplification. Gain.

## 1. The Noise Floor
Every circuit has static hiss (Heat noise).
If you catch 1000 photons (Bright light), the signal (1000) drowns out the noise (1). SNR is high. Clean image.
If you catch 10 photons (Dark room), the noise (1) is 10% of the signal.
When you turn up the ISO, you amplify the Signal *and* the Noise.
**ISO Invariance:**
On modern Sony/Fuji sensors, ISO is applied *after* the analog-to-digital conversion (or is parallel).
This means shooting at ISO 100 (underexposed) and brightening it in Photoshop gives the **Exact Same Image** as shooting at ISO 1600 in camera.
The "grain" is identical.
You don't need to fear the ISO dial. It's just metadata.

## 2. Dual Native ISO
Cinema cameras (Red, Sony FX3) have a trick.
Two circuits.
Circuit A: Optimized for ISO 800 (Daylight).
Circuit B: Optimized for ISO 12,800 (Night).
When you switch to High ISO, the camera physically rewires its sensor capacitors to handle low light better.
The noise *drops* when you hit 12,800.
It's like shifting gears in a car.

## 3. The Megapixel Myth
"More Megapixels = Better." No.
If you put 100MP on a tiny phone sensor... the pixels are tiny buckets.
They catch fewer photons.
They are noisier.
A 12MP sensor (Sony A7S) has huge pixels. It can see in the dark.
Resolution vs Sensitivity is a zero-sum game.

### Fact Box
*   **Ettr (Expose to the Right):** The best way to reduce noise is to overexpose the image (without clipping highlights). Fill the bucket. Then darken it in post. This pushes the signal far above the noise floor.
        `,
    },
    {
        slug: "bayer-filter-demosaicing",
        title: "You Are Colorblind: The Bayer Filter",
        description: "Your camera sensor only sees Black and White. We have to paint the colors on top mathematically. The Demosaicing algorithm.",
        category: "Photography",
        publishedAt: "2024-12-21",
        imageUrl: "/images/bayer-pattern.png",
        tags: ["Photography", "Tech", "Math", "Deep Dive"],
        content: `
## Introduction: Silicon is Monochrome
Silicon absorbs light. It counts electrons.
It doesn't care if the photon is Red or Blue.
So how do we get color photos?
**The Mosaic.**

## 1. The Checkerboard (Bryce Bayer 1976)
We paint tiny filters over the pixels.
**R G G B**
Red, Green, Green, Blue.
Why 2 Greens? Because the human eye is most sensitive to Green (evolution: spotting predators in grass).
**The Interpolation:**
If pixel 1 knows it is Red...
It looks at neighbors 2 and 4 (Green) and neighbor 5 (Blue) to *guess* what its Green and Blue values should be.
It is an estimation game.
**MoirÃ© Patterns:**
If you photograph a checked shirt, the pattern interferes with the Bayer grid. You get weird rainbow swirls.
Cameras use "Anti-Aliasing Filters" (Blur filters) to stop this.

## 2. Foveon Sensors (The Rebel)
Sigma cameras use Foveon sensors.
They stack the pixels vertically (Silicon absorbs different colors at different depths).
Top layer = Blue. Middle = Green. Bottom = Red.
No guessing. No fabrication.
**Pros:** Incredible color accuracy. Looks like film.
**Cons:** Terrible in low light (the bottom layer gets no light).
It remains a cult product.

## 3. Computational Photography (Google Pixel)
Phones have tiny sensors.
They cheat.
When you take 1 photo, they take 9 photos.
Some underexposed (for highlights), some overexposed (for shadows).
They align them. They average the noise out.
They use AI to "Hallucinate" detail that the lens didn't resolve.
Your iPhone photo is not a capture of reality. It is a painting generated by a neural network interpretation of reality.

### Fact Box
*   **Kodachrome:** The most famous film stock. It didn't have color dye in the film. The dye was added *during development* (a nightmare chemical process). It was Archival (lasted 100 years). Digital files rot (Bit rot) faster than Kodachrome fades.
        `,
    },
    {
        slug: "lens-optics-bokeh-physics",
        title: "Glass Physics: Why Bokeh Happens",
        description: "Why is the background blurry? It's not just 'Art'. It's the Circle of Confusion. The math of f/1.8.",
        category: "Photography",
        publishedAt: "2024-12-22",
        imageUrl: "/images/bokeh-diagram.png",
        tags: ["Photography", "Physics", "Optics", "Deep Dive"],
        content: `
## Introduction: The Pinpoint
Ideally, a point of light in the world becomes a point of light on the sensor.
But light bends.
If the lens is "Out of Focus", the point hits the sensor as a disc.
**The Circle of Confusion.**

## 1. Aperture (The Pupil)
f-stop = Focal Length / Diameter.
f/1.8 is a huge hole.
Light comes from extreme angles.
This creates a shallow "Depth of Field".
Only a thin slice of the world creates "Points". Everything else creates "Discs".
These discs overlap to create **Bokeh** (Japanese for Blur).
f/22 is a tiny pinhole. Light comes straight. Everything is sharp.

## 2. Lens Character (Imperfection)
A perfect lens (Computer) renders perfect Gaussian blur. Boring.
Vintage lenses (Helios 44-2) have "Swirly Bokeh".
Why?
**Cat's Eye Effect:**
The lens barrel blocks the light at the edges. The bokeh balls get squashed into lemons.
**Spherical Aberration:**
Light from the edge of the lens focuses closer than light from the center. It creates a "Glow".
Photographers pay thousands for these "Flaws". Character > Perfection.

## 3. Diffraction (The Limit)
If you stop down to f/32 to get everything sharp...
The hole is so small that light waves scrape the edges and interfere.
The image gets **Softer**.
Most lenses are sharpest at f/5.6 or f/8.
Physics puts a hard limit on sharpness.

### Fact Box
*   **Anamorphic Lenses:** Used in movies (JJ Abrams). They squeeze a wide image onto a square sensor. This creates the oval bokeh and the horizontal blue lens flares. It looks "Cinematic".
        `,
    },
    {
        slug: "flash-sync-speed-shutter",
        title: "Freezing Time: Shutter Mechanics",
        description: "Why can't you use flash at 1/8000th of a second? The Rolling Shutter problem and High Speed Sync.",
        category: "Photography",
        publishedAt: "2024-12-23",
        imageUrl: "/images/shutter-curtain.png",
        tags: ["Photography", "Physics", "Tech", "Deep Dive"],
        content: `
## Introduction: The Curtain
A mechanical shutter has two curtains.
1.  First curtain opens. (Sensor exposed).
2.  Second curtain closes. (Sensor covered).

## 1. Sync Speed (The Limit)
At 1/200th of a second, the first curtain is fully open before the second starts closing.
The sensor is 100% visible.
**FLASH.**
The light hits the whole sensor.
At 1/8000th... the second curtain chases the first curtain.
There is never a fully open sensor. Just a moving "Slit".
If you flash now... you only light up the slit.
You get a black bar on your photo.

## 2. Rolling Shutter (The Jello)
Electronic shutters (Video) read the sensor line by line.
Top to Bottom.
This takes time (15ms).
If you whip the camera... the bottom of the image is recorded *after* the top.
Telephone poles lean. Propellers look like boomerangs.
**Global Shutter:**
New cameras (Sony A9 III) read all pixels instantly.
No Jello. No Sync Speed limit. Flash at 1/80,000th.
It is the holy grail.

## 3. High Speed Sync (HSS)
How to cheat the mechanical limit?
Make the flash pulse like a strobe light (50,000 times a second).
As the slit moves down the sensor, the flash stays on.
**Downside:** It eats battery power. The flash is weaker.
But it lets you shoot portraits in bright sun at f/1.4 with a dark background.

### Fact Box
*   **Bullet Time:** In *The Matrix*, they used 120 cameras arranged in a circle. They fired them sequentially. It wasn't slow motion; it was distinct still images played as a movie.
        `,
    },
    {
        slug: "color-theory-gamut-srgb",
        title: "Colors You Can't See: Color Spaces",
        description: "Your monitor is lying to you. The world has colors that cannot be displayed on a screen. The logic of sRGB, AdobeRGB, and ProPhoto.",
        category: "Photography",
        publishedAt: "2024-12-24",
        imageUrl: "/images/chromaticity-diagram.png",
        tags: ["Photography", "Physics", "Tech", "Deep Dive"],
        content: `
## Introduction: The Horseshoe
Look at the CIE Chromaticity Diagram (the rainbow horseshoe).
This is every color a Human can see.
Now look at the triangle inside it.
That is **sRGB**. The internet standard.
It is tiny. It misses Cyans and saturated Greens.
Most of the "Neon" colors of the world fit inside the horseshoe but outside the triangle.

## 1. AdobeRGB vs ProPhoto
**AdobeRGB:** Bigger triangle. Used for printing (CMYK printers produce colors sRGB can't show).
**ProPhoto RGB:** Massive triangle. It goes *outside* the horseshoe (imaginary colors).
If you shoot RAW, you capture ProPhoto.
If you edit in sRGB... you are throwing away 30% of your colors before you start.
**The Danger:**
If you export ProPhoto to the web... browsers don't understand it. They treat it as sRGB.
The colors look washed out and grey.
You must "Convert to Profile" at the very end.

## 2. Bit Depth (Banding)
8-bit = 256 shades of Red.
16.7 Million Colors total.
Sounds like a lot?
Look at a blue sky. It's a gradient.
If you only have 256 blues... you see stripes (**Banding**).
**10-bit (HDR):**
1024 shades of Red.
1 Billion Colors.
No banding. Smoother gradients.
Cinema uses 12-bit or 16-bit.

## 3. White Balance (Kelvin)
The sun is 5500K (White).
A candle is 2000K (Orange).
Shade is 8000K (Blue).
Your brain auto-corrects this (Chromatic Adaptation). A white paper looks white in candlelight.
A camera is dumb. You have to tell it "White is 5500K".
If you shoot RAW, you can change this later.
If you shoot JPEG, the camera bakes it in. You can't fix orange skin later.

### Fact Box
*   **The Dress:** Blue/Black or White/Gold? It was a White Balance illusion. People who assumed the dress was in shadow (Blue light) subtracted the blue and saw White/Gold. People who assumed it was in bright light saw Blue/Black.
        `,
    },
];
